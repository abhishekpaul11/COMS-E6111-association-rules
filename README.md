# COMS-E6111-association-rules
Using Apriori algorithm to generate frequent itemsets from a particular dataset and then extracting association rules from them.

## Team
1. Abhishek Paul (ap4623)
2. Puja Singla (ps3467)

## Files submitted
1. [data](/data) --> Folder that contains the raw data files that were used to create the [INTEGRATED-DATASET.csv](/INTEGRATED-DATASET.csv) for itemset generation.
   1. [parking_first_march_2025.csv](/data/parking_first_march_2025.csv) --> Raw dataset downloaded from [NYC Open Data](https://opendata.cityofnewyork.us/data/) site. It provides data on parking violations issued in New York City on 1st March, 2025.
   2. [ParkingViolationCodes_January2020.xlsx](/data/ParkingViolationCodes_January2020.xlsx)  --> Excel file downloaded from [here](https://data.cityofnewyork.us/api/views/pvqr-7yc4/files/7875fa68-3a29-4825-9dfb-63ef30576f9e?download=true&filename=ParkingViolationCodes_January2020.xlsx), which contains the mapping of a Violation Code to its description and fine. Acts as a lookup table for itemset creation.
2. [.gitignore](.gitignore) --> Gitignore file for python projects
3. [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv) --> A csv file generated after [preprocess.py](preprocess.py). Each row in it is treated as an item basket or a transaction, which will be used by the apriori algorithm and for extracting association rules later.
4. [LICENSE](LICENSE) --> MIT License
5. [output.txt](output.txt) --> The output file generated by a compelling sample run of the program on the chosen dataset with a minimum support of 5% and a minimum confidence of 50%.
6. [main.py](main.py) --> The main entry point of the application, which also contains code for the apriori algorithm and for extracting association rules.
7. [preprocess.py](preprocess.py) --> Contains code cleaning and pre-processing the raw data files under [data](/data) folder, and generating [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv).
8. [README.md](README.md) --> Project Readme file
9. [requirements.txt](requirements.txt) --> List of dependencies and external libraries used


## Installation and Execution

You can clone the repo using the command given below,

```bash
git clone https://github.com/abhishekpaul11/COMS-E6111-association-rules.git
```
or download a zip file of this repo.

Once, you're in the repository in your terminal, type the following commands

### Create a virtual environment

```bash
python3 -m venv venv
```

### Activate the virtual environment

```bash
source venv/bin/activate
```

### Install all the required dependencies

```bash
pip3 install -r requirements.txt
```

### Run the application

```bash
python3 main.py INTEGRATED-DATASET.csv <min_sup> <min_conf>
```

where,<br>
`[min_sup]` and `<min_conf>` are both numbers between 0 and 1, signifying minimum support for itemset generation from the market baskets and minimum confidence for the association rules respectively.

**Note**<br>
1. The above instructions are mentioned for macOS / Linux systems. Run the appropriate commands if you are using a Windows System.

**Assumption**<br>
You have python3 and pip3 available in your system.
If not, you can get it from [Python Downloads](https://www.python.org/downloads/) and
[Pip Installation](https://pip.pypa.io/en/stable/installation/) respectively.


## Dataset Source and Pre-processing

### (a) NYC Open Data Set Used

The dataset used to generate the [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv) file is:

**Title:** [Parking Violations Issued - Fiscal Year 2024](https://data.cityofnewyork.us/City-Government/Parking-Violations-Issued-Fiscal-Year-2024/pvqr-7yc4)  
**Publisher:** New York City Open Data  
**Date Filter:** March 1st, 2025
**Format:** CSV  
**Record Count:** 43,327 rows

### (b) Dataset Transformation

To construct the [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv), the following high-level preprocessing and transformation steps were applied:

1. **Filtering by Date**
- Only records where the `Issue Date` is **March 1st, 2025** were retained. <br>
<br>

2. **Violation Code Mapping**
- A secondary reference file, [ParkingViolationCodes_January2020.xlsx](/data/ParkingViolationCodes_January2020.xlsx), available as an attachment in the primary dataset page itself was used to map:
  - `Violation Code` → `Violation Description`
  - `Violation Code` → `Fine Amount`
- Mappings were applied to create human-readable and discretized categories. <br>
<br>

3. **Attribute Transformation and Discretization**
- **Time Discretization**
  - `Violation Time` was parsed and categorized into four bins: `Morning`, `Afternoon`, `Evening`, and `Night`. <br>
<br>

   - **Fine Discretization**
     - Fines were bucketed into `Low Fine` (<$50), `Medium Fine` ($50–$100), and `High Fine` (>$100). <br>
<br>

- **Vehicle Type Standardization**
     - Vehicle body types (e.g., `SDN`, `SUBN`, `VAN`, `PICK`) were mapped to generalized types like `Sedan`, `SUV`, `Van`, `Pickup`, etc. <br>
<br>

- **Geographic Mapping**
     - The `Violation County` was mapped to the corresponding NYC borough using a fixed lookup table:
       - `NY` -> `Manhattan`
       - `MN` -> `Manhattan`
       - `BK` -> `Brooklyn`
       - `K` -> `Brooklyn` // King's County
       - `Kings` -> `Brooklyn`
       - `QN` -> `Queens`
       - `Q` -> `Queens`
       - `Qns` -> `Queens`
       - `BX` -> `Bronx`
       - `Bronx` -> `Bronx`
       - `R` -> `Staten Island` // Richmond County
       - `ST` -> `Staten Island` <br>
<br>

4. **Row Filtering for Completeness and Usefulness**
- Rows missing critical information were excluded.
- Transactions were required to contain **at least 4 informative attributes** and exclude vague categories like `"Unknown"` or `"Other"` vehicle types. <br>
<br>

5. **Final Transaction Format**
- Each row in [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv) represents a "market basket" in the form of:
  ```csv
  Borough,Time Period,Fine Level,Vehicle Type,Violation Code,Violation Description
  ```
- All entries are comma-separated on a single line.
- The final file has around 33,435 transactions are pre-processing 43,327 rows.


### (c) Justification for Dataset Choice

The NYC Parking Violations dataset is a compelling source for association rule mining due to the following reasons:

- **Rich Attribute Variety**: It contains structured data across time, geography, vehicle characteristics, and offense types.
- **High Cardinality and Volume**: The dataset includes thousands of violations daily, enabling meaningful support and confidence thresholds.
- **Real-World Behavioral Insights**:
  - The dataset reflects tangible patterns in driver behavior, enforcement zones, and common offenses.
  - Association rules derived from such data can surface actionable insights for city planners and transportation officials (e.g., identifying high-risk areas or peak violation times for specific boroughs and vehicle types).
- **Temporal and Spatial Dimensions**:
  - Combining time-of-day, borough, and vehicle characteristics adds multidimensional context to the patterns discovered.

This combination of depth, breadth, and real-world relevance makes it ideal for uncovering interesting, potentially surprising associations via the Apriori algorithm.

## Internal Project Design

The project implements the Apriori algorithm to mine frequent itemsets and generate association rules from the [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv). The implementation follows the standard Apriori framework as mentioned in Section 2.1.1. in [Fast Algorithms for Mining Association Rules by Agrawal and Srikant](https://www.cs.columbia.edu/~gravano/Qual/Papers/agrawal94.pdf), but includes optimizations and variations to handle the large dataset efficiently. The core components are:

### Data Loading
The [load_transactions()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L6) function reads the INTEGRATED-DATASET CSV file and loads transactions into memory as a list of sets for faster processing. It also identifies frequent 1-itemsets during this step to bootstrap the Apriori process.

### Frequent Itemset Generation
The [apriori()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L97) function iteratively generates frequent itemsets using the [generate_candidates()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L54) function, which includes a pruning step (as confirmed in the previous response). The pruning ensures that only candidates with all frequent (k-1)-subsets are evaluated, reducing the search space.<br><br>
The [count_support()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L37) function computes the support of candidate itemsets by scanning the transactions, and [filter_frequent_itemsets()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L47) retains those above the minimum support threshold.

### Rule Generation
The [get_rules()](https://github.com/abhishekpaul11/COMS-E6111-association-rules/blob/a8207996fefed348edd7f3dd765a138e0412b341/main.py#L131) function generates association rules from frequent itemsets by computing confidence and filtering rules above the minimum confidence threshold. It uses support values directly, avoiding additional transaction scans.

### Output
The results (frequent itemsets and rules) are written to an [output.txt](output.txt) file, formatted as specified, with support percentages and confidence for rules.

## Variations to Standard Apriori

Several sophisticated enhancements were implemented based on Chapter 6 of [Mining of Massive Datasets (MMDS)](http://infolab.stanford.edu/~ullman/mmds/ch6.pdf):

1. **Hierarchical Item Relationships** (Implemented in `load_transactions()`)
   - Created a composite item: `Violation_<Code>_<Description>`
   - Created a hierarchical item: `<FineLevel>_Violation_<Code>_<Description>`<br><br>

    **Justification**
    - Reflects **semantic hierarchies**.
    - Reduces itemset dimensionality (from 6 to 5 fields).
    - Captures domain logic (e.g., fine level is derived from violation type).
    - Enables interpretable rules such as:  
    `[Manhattan, SUV] => [HighFine_Violation_40_DOUBLE_PARKING]`<br><br>

2. **Maximal Frequent Itemsets** (Implemented in `find_maximal_frequent_itemsets()` and `generate_rules()`)
   - Identified only **maximal frequent itemsets** for rule generation.
   - Eliminated subset-based redundancy by skipping non-maximal sets.
   - Ensured that RHS of rules never includes **hierarchical items**.<br><br>

    **Justification**
    - Inspired by MMDS Section 6.4.
    - Reduces computational overhead during rule generation.
    - Improves clarity and reduces duplication in resulting rules.<br><br>

3. **Pruning of Trivial and Redundant Rules** (Implemented in `generate_rules()`)

   - Skipped rules where the RHS was implied by the LHS due to hierarchical structure.
   - Example excluded rule:
     `[MediumFine_Violation_14_..., Sedan, Violation_14_...] => [MediumFine]`
   - Skipped any rule where RHS was `"Low Fine"`, `"Medium Fine"`, or `"High Fine"` **already encoded in the LHS**.<br><br>

    **Justification**
   - Avoids generating obvious or tautological rules.
   - Keeps the final output concise and human-interpretable.

## Compelling Sample Run

```bash
python3 main.py INTEGRATED-DATASET.csv 0.05 0.5
```
This comprises processing [INTEGRATED-DATASET.csv](INTEGRATED-DATASET.csv) to generate [output.txt](output.txt) with frequent itemsets with minimum support of 5% and minimum confidence of 50%.
For example,

### Sample Rule 1  
`[Medium Fine, Medium Fine_Violation_71_INSP. STICKER-EXPIRED/MISSING, Violation_71_INSP. STICKER-EXPIRED/MISSING] => [Morning]` 
- **Confidence:** 76.9%  
- **Support:** 5.7%

**Implication**  
Inspection sticker violations (Code 71) are most frequently cited in the **morning** when cars are first observed.

**Plausibility**  
Morning patrols catch cars left overnight or starting their day; stickers are easy to inspect while parked.

**Actionable Insight**  
Send early-hour reminders for inspection deadlines; focus enforcement during morning sweeps.

### Sample Rule 2  
`[Medium Fine, Medium Fine_Violation_36_PHTO SCHOOL ZN SPEED VIOLATION, Queens, Violation_36_PHTO SCHOOL ZN SPEED VIOLATION] => [SUV]`  
- **Confidence:** 63.7%  
- **Support:** 7.8%

**Implication**  
School zone speed violations in **Queens** are more likely to involve **SUVs**.

**Plausibility**  
SUVs are common for school drop-offs; speed cameras capture violations consistently during peak hours.

**Actionable Insight**  
Deploy SUV-targeted speed awareness in Queens school zones; install radar feedback signs.

### Sample Rule 3  
`[Brooklyn, Medium Fine, Morning] => [SUV]` 
- **Confidence:** 61.7%  
- **Support:** 5.2%

**Implication**  
In **Brooklyn**, violations that occur in the **morning** and result in **medium fines** often involve **SUVs**.

**Plausibility**  
SUVs may more easily violate parking or curb restrictions on narrower Brooklyn streets.

**Actionable Insight**  
Review signage in constrained areas; inform SUV owners of common violations through alerts or flyers.
